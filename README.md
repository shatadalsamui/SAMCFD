# CFD-Broker: Real-Time CFD Trading Platform

CFD-Broker is a **production-grade, event-driven trading platform** for Contracts for Difference (CFDs), built for **scalability, reliability, and ultra-low-latency performance**. The platform features secure user authentication, high-frequency price streaming, and a modern web interface for trading simulations. Architected as a monorepo with Turborepo, it leverages a **microservices architecture** powered by the Bun runtime, Kafka for asynchronous messaging, Redis for low-latency caching, and PostgreSQL for robust data persistence.

---

## üöÄ Key Features & Metrics

- **Massive User Scalability:** Designed to support 100,000+ registered users per moderate instance (2-4 vCPUs, 8GB RAM), with seamless horizontal scaling.
- **Ultra-Low-Latency Streaming:** Real-time price updates delivered to 1,000+ concurrent WebSocket clients with <50ms end-to-end latency.
- **High-Throughput Authentication:** Auth requests processed in ~200ms (Kafka round-trip + bcrypt), supporting secure, high-volume flows.
- **Event-Driven Microservices:** Decoupled services for API, DB processing, polling, and frontend, enabling independent scaling and rapid iteration.
- **Resilient & Fault-Tolerant:** Kafka-based messaging ensures async processing, high throughput, and robust error handling.
- **Developer Experience:** TypeScript throughout, Zod for schema validation, reusable UI components, unified linting/formatting, and hot reload for rapid development.
- **Security-First:** JWT-based authentication, bcrypt password hashing, OTP via email, and Redis-backed session management.

---

## üèóÔ∏è Architecture Overview

CFD-Broker is a **microservices-based platform** using event-driven communication via Kafka, in-memory caching with Redis, and PostgreSQL for persistence. All services are container-ready and can be orchestrated via Docker Compose or Kubernetes.

### High-Level Architecture Diagram

```mermaid
graph TB
    subgraph "Frontend Layer"
        Web[Web App<br/>Next.js<br/>Port: 3000]
    end

    subgraph "API Layer"
        API[API Server<br/>Express.js + TS<br/>Ports: 3001 (HTTP), 8080 (WS)]
    end

    subgraph "Messaging Layer"
        Kafka[Kafka<br/>Message Broker<br/>Topics:<br/>user-requests<br/>user-responses<br/>price-updates]
    end

    subgraph "Processing Layer"
        DBProc[DB Processor<br/>Bun + KafkaJS<br/>Prisma ORM]
        Poller[Poller<br/>Bun + WS Client<br/>Backpack Exchange]
    end

    subgraph "Data Layer"
        DB[(PostgreSQL<br/>User Table)]
        Redis[(Redis<br/>OTP Cache<br/>Session Tokens<br/>Price Cache)]
    end

    subgraph "External Services"
        Email[Gmail SMTP<br/>OTP Emails]
        Backpack[Backpack Exchange<br/>Real-Time Prices]
    end

    Web -->|HTTP/WS| API
    API -->|Produce| Kafka
    API -->|Cache Ops| Redis
    API -->|Send OTP| Email
    Poller -->|Poll Prices| Backpack
    Poller -->|Produce| Kafka
    Kafka -->|Consume| DBProc
    DBProc -->|Read/Write| DB
    DBProc -->|Produce Responses| Kafka
    Kafka -->|Consume Responses| API
    API -->|Broadcast Prices| Web
```

---

## üß© Project Structure

```
apps/
‚îú‚îÄ‚îÄ api-server/          # Express.js API server (auth, prices, WebSocket)
‚îú‚îÄ‚îÄ db-processor/        # Kafka consumer for DB operations
‚îú‚îÄ‚îÄ poller/              # WebSocket poller for real-time prices
‚îî‚îÄ‚îÄ web/                 # Next.js frontend app
docs/                    # Architecture, flow, and sequence diagrams
packages/                # Shared libraries
‚îú‚îÄ‚îÄ db/                  # Prisma client and migrations
‚îú‚îÄ‚îÄ eslint-config/       # ESLint configurations
‚îú‚îÄ‚îÄ kafka/               # Kafka producer/consumer client
‚îú‚îÄ‚îÄ redis/               # Redis client
‚îú‚îÄ‚îÄ schemas/             # Zod validation schemas
‚îú‚îÄ‚îÄ typescript-config/   # TypeScript configurations
‚îî‚îÄ‚îÄ ui/                  # Reusable React components
```

---

## üõ†Ô∏è Microservices & Packages

### API Server ([`apps/api-server`](apps/api-server))
- **Express.js + TypeScript**: Handles HTTP requests for authentication (signup, signin, verify OTP, logout, /me) and price queries.
- **WebSocket Server**: Broadcasts real-time price updates to all connected clients.
- **Kafka Integration**: Uses request-response pattern for user existence/auth/creation, ensuring async, decoupled flows.
- **Redis Caching**: Stores OTPs, JWT sessions, and price snapshots for low-latency access.
- **Email Service**: Sends OTPs via Gmail SMTP, with robust error handling and logging.
- **Security**: JWT tokens (httpOnly cookies), bcrypt password hashing, Zod input validation.

### DB Processor ([`apps/db-processor`](apps/db-processor))
- **Kafka Consumer**: Listens for user existence, creation, and authentication requests.
- **Prisma ORM**: Handles all DB operations (user CRUD) with PostgreSQL.
- **Stateless & Scalable**: Can be horizontally scaled for high-throughput DB workloads.

### Poller ([`apps/poller`](apps/poller))
- **WebSocket Client**: Connects to Backpack Exchange for real-time price data (SOL_USDC, BTC_USDC, ETH_USDC, DOGE_USDC, BNB_USDC).
- **Kafka Producer**: Publishes validated price updates to the `price-updates` topic.
- **Auto-Reconnect**: Handles disconnections and rate limits gracefully.
- **Schema Validation**: Uses Zod to ensure all price data is well-formed before publishing.

### Web App ([`apps/web`](apps/web))
- **Next.js + React**: Modern, responsive UI for trading, signup/signin, OTP verification, and live price dashboard.
- **WebSocket Client**: Receives real-time price updates from the API server.
- **Reusable UI**: Leverages `@repo/ui` for consistent design and rapid prototyping.

### Shared Packages

- **`@repo/ui`** ([`packages/ui`](packages/ui)): Reusable React components (Button, Card, Code, etc.).
- **`@repo/schemas`** ([`packages/schemas`](packages/schemas)): Zod schemas for all validation (Signup, Signin, OTP, PriceUpdate).
- **`@repo/kafka`** ([`packages/kafka`](packages/kafka)): Singleton Kafka producer/consumer with group management.
- **`@repo/redis`** ([`packages/redis`](packages/redis)): Redis client with connection pooling and health checks.
- **`@repo/db`** ([`packages/db`](packages/db)): Prisma client, migrations, and seed scripts.
- **`@repo/eslint-config` & `@repo/typescript-config`**: Unified linting and TS settings for all packages.

---

## üî• Complex Implementations & Highlights

- **Kafka Request-Response Pattern:**  
  The API server uses a robust request-response pattern over Kafka for all user-related flows (existence check, creation, authentication), with correlation IDs and pending request maps for reliable async communication.

- **Fire-and-Forget Kafka for Price Streaming:**  
  Price updates are streamed from the poller to the API server via a dedicated Kafka topic. The API server consumes these updates, broadcasts them over WebSocket, and caches them in Redis for instant HTTP retrieval.

- **Atomic OTP Handling:**  
  OTPs are hashed and stored in Redis with TTL. Verification is atomic: OTPs are deleted immediately after use to prevent replay attacks, and all flows are race-condition safe.

- **WebSocket Broadcasting at Scale:**  
  The API server maintains a set of connected WebSocket clients and broadcasts validated price updates in real time, supporting thousands of concurrent connections with efficient memory usage.

- **Schema-Driven Validation:**  
  All data entering or leaving the system is validated with Zod schemas, ensuring strict type safety and preventing malformed data from propagating.

- **Stateless, Horizontally Scalable Services:**  
  All microservices are stateless and can be scaled independently. Kafka and Redis provide the glue for distributed coordination and caching.

- **Developer Experience:**  
  Hot reload, unified linting, and shared TS configs make for a seamless developer workflow. All flows are documented with sequence diagrams in `/docs`.

---

## ‚ö° Performance Benchmarks

- **Signup:** ~3.5s (email bottleneck via SMTP)
- **Signin:** ~200ms (Kafka round-trip + bcrypt)
- **Verify OTP:** ~270ms (Kafka + DB write)
- **Logout/Me:** <10ms (Redis)
- **Price Updates:** <50ms end-to-end (poller ‚Üí Kafka ‚Üí API ‚Üí WebSocket ‚Üí client)
- **WebSocket Clients:** 1,000+ per API server instance (can scale horizontally)
- **Kafka Throughput:** 10,000+ messages/sec per broker (with tuning)
- **Redis Ops:** 100,000+ ops/sec (in-memory)

---

## üè¢ Setup & Installation

### Prerequisites

- [Bun](https://bun.sh/) (runtime for all services)
- [PostgreSQL](https://www.postgresql.org/)
- [Redis](https://redis.io/)
- [Kafka](https://kafka.apache.org/) (e.g., via Docker)
- Gmail account for SMTP (with app password)

### Installation

1. **Clone the repo:**  
   `git clone <repo-url>`

2. **Install dependencies:**  
   `bun install`

3. **Set up environment variables:**  
   Copy `.env.example` to `.env` in each app/package and fill in the values:
   - [`apps/api-server/.env`](apps/api-server/.env): `PORT=3001`, `JWT_SECRET=...`, `GMAIL_USER=...`, `GMAIL_APP_PASSWORD=...`, `WS_PORT=8080`
   - [`packages/kafka/.env.example`](packages/kafka/.env.example): `KAFKA_BROKER=localhost:9092`
   - [`packages/redis/.env.example`](packages/redis/.env.example): `REDIS_URL=redis://localhost:6379`
   - [`packages/db/env.example`](packages/db/env.example): `DATABASE_URL=postgresql://user:pass@localhost:5432/cfdbroker`
   - [`apps/poller/src/config.ts`](apps/poller/src/config.ts): `BACKPACK_WS_URL=wss://ws.backpack.exchange/`

4. **Run DB migrations:**  
   `cd packages/db && bun run db:push`

5. **Seed DB (optional):**  
   `bun run prisma/seed.ts`

---

## üèÉ Running the Project

Use Turborepo for development:

```sh
# Start all services
turbo dev

# Or start individually
turbo dev --filter=api-server
turbo dev --filter=web
turbo dev --filter=poller
turbo dev --filter=db-processor
```

- **API Server:** `bun run start` in [`apps/api-server`](apps/api-server)
- **Web App:** `npm run dev` in [`apps/web`](apps/web)
- **Poller:** `bun run dev` in [`apps/poller`](apps/poller)
- **DB Processor:** `bun run dev` in [`apps/db-processor`](apps/db-processor)

> **Ensure Kafka, Redis, and PostgreSQL are running (e.g., via Docker Compose).**

---

## üìà Scalability & Production Notes

- **Stateless Services:** All services can be scaled horizontally (multiple API servers, DB processors, pollers).
- **Kafka & Redis:** Cluster for high throughput and failover.
- **WebSocket Clustering:** Use sticky sessions or Redis pub/sub for 10k+ concurrent clients.
- **Email Bottleneck:** For high signup rates, switch from Gmail SMTP to a transactional email provider (e.g., SES, SendGrid, Resend).
- **Monitoring:** Integrate Prometheus/Grafana for metrics, and use centralized logging.
- **Security:** Always use HTTPS in production, rotate JWT secrets, and restrict environment variable access.

---

## üìö Documentation

- **Architecture & Flows:** See [`docs/architecture.md`](docs/architecture.md), [`docs/signup-flow.md`](docs/signup-flow.md), [`docs/signin-flow.md`](docs/signin-flow.md), [`docs/verify-otp-flow.md`](docs/verify-otp-flow.md), [`docs/logout-flow.md`](docs/logout-flow.md), [`docs/me-flow.md`](docs/me-flow.md)
- **Codebase:** All services and packages are documented inline with JSDoc and comments.

---

## ü§ù Contributing

- Follow ESLint/Prettier rules.
- Use Zod for validation.
- Test Kafka/Redis connections before pushing.
- Update docs for new features and flows.

---

## üîó Useful Links

- [Turborepo Docs](https://turborepo.com/docs)
- [Prisma Docs](https://www.prisma.io/docs)
- [KafkaJS Docs](https://kafka.js.org/)
- [Backpack Exchange API](https://docs.backpack.exchange/)

---

For issues, open a PR or issue in the repo.  
**CFD-Broker: Built for scale. Engineered for speed. Designed for developers.**